include "shader_global.dshl"
include "vtex.dshl"
include "clipmap_feedback_common.dshl"
include "hardware_defines.dshl"



hlsl
{
  uint calc_histogram_index(uint x, uint y, uint mip, uint ri_offset)
  {
    return (mip << (TILE_WIDTH_BITS + TILE_WIDTH_BITS + MAX_RI_VTEX_CNT_BITS)) | (ri_offset << (TILE_WIDTH_BITS + TILE_WIDTH_BITS)) | (y << TILE_WIDTH_BITS) | (x);
  }
}



buffer clipmap_histogram_buf_rw;
buffer clipmap_tile_info_buf_rw;

macro CLIPMAP_CLEAR_HISTOGRAM(stage)
  (stage) {
    clipmap_histogram_buf_rw@uav = clipmap_histogram_buf_rw hlsl {
      RWByteAddressBuffer clipmap_histogram_buf_rw@uav;
    }
    clipmap_tile_info_buf_rw@uav = clipmap_tile_info_buf_rw hlsl {
      RWByteAddressBuffer clipmap_tile_info_buf_rw@uav;
    }
  }

  hlsl(stage)
  {
    void clearHistogram(uint dtId)
    {
      if (dtId >= CLIPMAP_HIST_TOTAL_ELEMENTS)
        return;

      if (dtId == 0)
        storeBuffer(clipmap_tile_info_buf_rw, 0, 0);

      storeBuffer(clipmap_histogram_buf_rw, dtId*4, 0);
    }
  }
endmacro


shader clipmap_clear_histogram_cs
{
  ENABLE_ASSERT(cs)
  CLIPMAP_CLEAR_HISTOGRAM(cs)

  hlsl(cs)
  {
    [numthreads( 64, 1, 1)]
    void render_cs( uint dtId : SV_DispatchThreadID )
    {
      clearHistogram(dtId);
    }
  }

  compile("target_cs", "render_cs");
}




int clipmap_tex_mips = 6;
interval clipmap_tex_mips: other_low<4, n_4<5, n_5<6, n_6<7, n_7<8, other_high;

int feedback_downsample_dim = 2;
interval feedback_downsample_dim: dim_1 < 2, dim_2 < 4, dim_4 < 8, dim_8 < 16, dim_16 < 32, dim_other;

int clipmap_feedback_calc_histogram_on_gpu = 0;
interval clipmap_feedback_calc_histogram_on_gpu: no < 1, yes;

buffer clipmap_feedback_buf;
buffer clipmap_feedback_readback_buf_rw;
int clipmap_feedback_readback_size;
int clipmap_feedback_stride;
int clipmap_feedback_readback_stride;

shader clipmap_process_feedback_cs
{
  ENABLE_ASSERT(cs)

  USE_FEEDBACK_PACKER(cs)
  (cs)
  {
    clipmap_feedback_buf@buf = clipmap_feedback_buf hlsl { ByteAddressBuffer clipmap_feedback_buf@buf; };
    clipmap_feedback_readback_buf_rw@uav = clipmap_feedback_readback_buf_rw hlsl { RWByteAddressBuffer clipmap_feedback_readback_buf_rw@uav; };
    clipmap_feedback_readback_size@i1 = clipmap_feedback_readback_size;
    clipmap_tex_mips@i1 = clipmap_tex_mips;
  }
  if (clipmap_feedback_calc_histogram_on_gpu == yes)
  {
    (cs)
    {
      clipmap_histogram_buf_rw@uav = clipmap_histogram_buf_rw hlsl {
        RWByteAddressBuffer clipmap_histogram_buf_rw@uav;
      }
    }
  }
  if (feedback_downsample_dim != dim_1)
  {
    (cs)
    {
      clipmap_feedback_stride@i1 = clipmap_feedback_stride;
      clipmap_feedback_readback_stride@i1 = clipmap_feedback_readback_stride;
    }
  }

  if (feedback_downsample_dim == dim_2)
  {
    hlsl(cs) {#define DOWNSAMPLE_DIM 2 }
  }
  else if (feedback_downsample_dim == dim_4)
  {
    hlsl(cs) {#define DOWNSAMPLE_DIM 4 }
  }
  else if ( feedback_downsample_dim == dim_8 )
  {
    hlsl(cs) {#define DOWNSAMPLE_DIM 8 }
  }
  else if ( feedback_downsample_dim == dim_16 )
  {
    hlsl(cs) {#define DOWNSAMPLE_DIM 16 }
  }
  else if ( feedback_downsample_dim != dim_1 ) // fallback for >8K resolutions
  {
    (cs) { downsample_dim@i1 = feedback_downsample_dim;}
    hlsl(cs) {
      #define DOWNSAMPLE_DIM downsample_dim.x
      #define UNROLL
    }
  }

  hlsl(cs)
  {
    uint loadFeedback(uint dtId)
    {
##if feedback_downsample_dim == dim_1
      uint feedback = loadBuffer(clipmap_feedback_buf, dtId*4);
##else
      uint2 dtId2d;
      dtId2d.y = dtId / clipmap_feedback_readback_stride;
      dtId2d.x = dtId - dtId2d.y * clipmap_feedback_readback_stride;

      int flattenedId0 = (dtId2d.y * clipmap_feedback_stride + dtId2d.x) * DOWNSAMPLE_DIM;
      uint feedback = loadBuffer(clipmap_feedback_buf, flattenedId0*4);
      UNROLL
      for (uint j = 0; j < DOWNSAMPLE_DIM; ++j)
      {
        UNROLL
        for (uint i = 0; i < DOWNSAMPLE_DIM; ++i)
        {
          if (i == 0 && j == 0)
            continue;

          uint flattenedId = flattenedId0 + j*clipmap_feedback_stride + i;
          feedback = max(feedback, loadBuffer(clipmap_feedback_buf, flattenedId*4));
        }
      }
##endif
      return feedback;
    }

    [numthreads( 64, 1, 1)]
    void render_cs( uint dtId : SV_DispatchThreadID )
    {
      if (dtId >= clipmap_feedback_readback_size)
        return;

      uint2 pos; uint mip; uint ri_offset;
      unpackFeedbackInfo(loadFeedback(dtId), pos.xy, mip, ri_offset);

      if ( all(pos < TILE_WIDTH && mip < clipmap_tex_mips && ri_offset < MAX_VTEX_CNT) )
      {
##if clipmap_feedback_calc_histogram_on_gpu == yes
        uint histId = calc_histogram_index(pos.x, pos.y, mip, ri_offset);
        clipmap_histogram_buf_rw.InterlockedAdd(histId*4, 1u);
##endif
      }

      // pack again, but without dummy clear offset, to make it consistent (pack/unpack can use tricks)
      uint feedback = packFinalFeedbackInfo(pos.xy, mip, ri_offset);
      storeBuffer(clipmap_feedback_readback_buf_rw, dtId*4, feedback);
    }
  }

  compile("target_cs", "render_cs");
}





buffer clipmap_histogram_buf;


macro BUILD_TILE_INFO(stage)
  (stage)
  {
    clipmap_histogram_buf@buf = clipmap_histogram_buf hlsl { ByteAddressBuffer clipmap_histogram_buf@buf; };
    clipmap_tex_mips@i1 = (clipmap_tex_mips);
    clipmap_tile_info_buf_rw@uav = clipmap_tile_info_buf_rw hlsl {
      RWByteAddressBuffer clipmap_tile_info_buf_rw@uav;
    }
  }

  hlsl(stage)
  {
    static const uint4 BITS = uint4(TILE_PACKED_X_BITS, TILE_PACKED_Y_BITS, TILE_PACKED_MIP_BITS, TILE_PACKED_COUNT_BITS);
    static const uint4 SHIFT = uint4(0, BITS.x, BITS.x + BITS.y, BITS.x + BITS.y + BITS.z);
    static const uint4 MASK = (1U << BITS) - 1U;

    uint packTileInfo(uint x, uint y, uint mip, uint hist_cnt)
    {
      uint4 data = uint4(x, y, mip, hist_cnt);
      data = min(data, MASK); // Only count can be outside of bounds, but masking would make it overflow, so we use actual clamping. The rest is clamped as well for safety.
      data = data << SHIFT;
      return data.x | data.y | data.z | data.w;
    }

    void buildTileInfo(uint2 dtId)
    {
      if (any(dtId >= TILE_WIDTH))
        return;

##if clipmap_tex_mips == n_4
      #define UNROLLED_MIP_CNT 4
##elif clipmap_tex_mips == n_5
      #define UNROLLED_MIP_CNT 5
##elif clipmap_tex_mips == n_6
      #define UNROLLED_MIP_CNT 6
##elif clipmap_tex_mips == n_7
      #define UNROLLED_MIP_CNT 7
##endif

      UNROLL for (uint ri_offset = 0; ri_offset < MAX_VTEX_CNT; ++ri_offset)
      {
#ifdef UNROLLED_MIP_CNT
      UNROLL for (uint mip = 0; mip < UNROLLED_MIP_CNT; ++mip)
#else
      for (uint mip = 0; mip < clipmap_tex_mips; ++mip)
#endif
      {
        uint histId = calc_histogram_index(dtId.x, dtId.y, mip, ri_offset);
        uint histCnt = loadBuffer(clipmap_histogram_buf, histId*4);

        BRANCH
        if (histCnt > 0)
        {
          uint at;
          clipmap_tile_info_buf_rw.InterlockedAdd(0, 1u, at);
          ++at; // first entry is cnt

#if MAX_RI_VTEX_CNT_BITS > 0
          storeBuffer(clipmap_tile_info_buf_rw, (at*2 + 0)*4, packTileInfo(dtId.x, dtId.y, mip, histCnt));
          storeBuffer(clipmap_tile_info_buf_rw, (at*2 + 1)*4, ri_offset);
#else
          storeBuffer(clipmap_tile_info_buf_rw, at*4, packTileInfo(dtId.x, dtId.y, mip, histCnt));
#endif
        }
      }
      }
    }
  }
endmacro



shader clipmap_build_tile_info_cs
{
  ENABLE_ASSERT(cs)
  BUILD_TILE_INFO(cs)

  hlsl(cs)
  {
    [numthreads( 8, 8, 1)]
    void render_cs( uint2 dtId : SV_DispatchThreadID )
    {
      buildTileInfo(dtId);
    }
  }

  compile("target_cs", "render_cs");
}
